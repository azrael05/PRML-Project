{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"D:\\PRML\\train\\train\"\n",
    "german_path=r\"D:\\PRML\\train\\train\\Eng\"\n",
    "# train_path=\n",
    "# test_path=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "os.listdir(path)\n",
    "for file in os.listdir(path):\n",
    "    file_path=os.path.join(path,file)\n",
    "    if(re.match(\"de\",file)):\n",
    "        os.rename(file_path,os.path.join(german_path,file))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values=[]\n",
    "features_german=[]\n",
    "features_english=[]\n",
    "features_spanish=[]\n",
    "sf=22050\n",
    "n_components=32\n",
    "max_iterations=100\n",
    "hop_len=int(0.01*sf)   ## hop length in milliseconds \n",
    "win_len=int(0.02*sf)   ## 20ms window length\n",
    "for folder in os.listdir(train_path):\n",
    "    folder_path=os.path.join(folder,file)\n",
    "    for file in os.listdir(folder_path):\n",
    "            \n",
    "            file_path=os.path.join(folder_path,file)\n",
    "            arr,sr=librosa.load(file_path,sr=sf)\n",
    "            arr=arr-np.mean(arr)\n",
    "            max = np.abs(arr).max()  \n",
    "            arr=arr/(1.01*max)\n",
    "            MFCC=librosa.feature.mfcc(arr,sr=sf,n_mfcc=14,dct_type=3,hop_length=hop_len, win_length=win_len,window='hann', n_mels=24)\n",
    "            MFCC=MFCC[1:14,:]\n",
    "            MFCC = np.reshape(MFCC,(len(MFCC[0]),len(MFCC)))\n",
    "            DMFCC=librosa.feature.delta(MFCC,order=1)\n",
    "            # BFCC=spafe.features.bfcc.bfcc(arr, fs=sf, num_ceps=13, win_len=win_len, win_hop=hop_len, win_type='hamming', nfilts=26, dct_type=3)\n",
    "            # BFCC=np.array(BFCC)\n",
    "            # print(BFCC.shape)\n",
    "            print(MFCC.shape)\n",
    "            Feature=np.concatenate((MFCC,DMFCC),axis=1)\n",
    "            if(re.match(\"de\",file)):\n",
    "                features_german=np.concatenate((features_german,Feature),axis=0)\n",
    "                true_values.append(0)\n",
    "            elif(re.match(\"en\",file)):\n",
    "                features_english=np.concatenate((features_english,Feature),axis=0)\n",
    "                true_values.append(1)\n",
    "            elif(re.match(\"es\",file)):\n",
    "                features_spanish=np.concatenate((features_spanish,Feature),axis=0)\n",
    "                true_values.append(2)\n",
    "\n",
    "german_model=GaussianMixture(n_components=n_components,covariance_type='diag',max_iter=max_iterations).fit(features_german)\n",
    "english_model=GaussianMixture(n_components=n_components,covariance_type='diag',max_iter=max_iterations).fit(features_english)\n",
    "spanish_model=GaussianMixture(n_components=n_components,covariance_type='diag',max_iter=max_iterations).fit(features_spanish)\n",
    "\n",
    "print(\"Training Done\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores=[]\n",
    "for folder in os.listdir(test_path):\n",
    "    for file in os.listdir(folder):\n",
    "        temp_score=[]\n",
    "        file_path=os.path.join(folder,file)\n",
    "        arr,sr=librosa.load(file_path,sr=sf)\n",
    "        arr=arr-np.mean(arr)\n",
    "        max = np.abs(arr).max()  \n",
    "        arr=arr/(1.01*max)\n",
    "        MFCC=librosa.feature.mfcc(arr,sr=sf,n_mfcc=14,dct_type=3,hop_length=hop_len, win_length=win_len,window='hann', n_mels=24)\n",
    "        MFCC=MFCC[1:14,:]\n",
    "        MFCC = np.reshape(MFCC,(len(MFCC[0]),len(MFCC)))\n",
    "        DMFCC=librosa.feature.delta(MFCC,order=1)\n",
    "        # BFCC=spafe.features.bfcc.bfcc(arr, fs=sf, num_ceps=13, win_len=win_len, win_hop=hop_len, win_type='hamming', nfilts=26, dct_type=3)\n",
    "        # BFCC=np.array(BFCC)\n",
    "        # print(BFCC.shape)\n",
    "        print(MFCC.shape)\n",
    "        Feature=np.concatenate((MFCC,DMFCC),axis=1)\n",
    "        temp_score.append(german_model.score(Feature))\n",
    "        temp_score.append(english_model.score(Feature))\n",
    "        temp_score.append(spanish_model.score(Feature))\n",
    "        Scores.append(temp_score)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52d90d3cc821dd0beedd6e719dbdecc722c226b9d90ed1b663c34e1877f1142e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
