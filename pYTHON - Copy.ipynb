{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoX could not be found!\n",
      "\n",
      "    If you do not have SoX, proceed here:\n",
      "     - - - http://sox.sourceforge.net/ - - -\n",
      "\n",
      "    If you do (or think that you should) have SoX, double-check your\n",
      "    path variables.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import spafe.features.bfcc as bfcc\n",
    "# from spafe.features.mfcc import mfcc\n",
    "import opensmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path=os.path(\"c\")\n",
    "max_count=4000  ## No. of examples to use for training\n",
    "# for i in os.listdir(path):\n",
    "#     new_path=os.path.join(path,i)\n",
    "#     for j in os.listdir(new_path):\n",
    "#         new_path1=os.path.join(new_path,j)\n",
    "#         os.mkdir(os.path.join(new_path1,\"English\"))\n",
    "#         os.mkdir(os.path.join(new_path1,\"German\"))\n",
    "#         os.mkdir(os.path.join(new_path1,\"Spanish\"))\n",
    "#         for k in os.listdir(new_path):\n",
    "#             if k.endswith(\".flac\"):\n",
    "#                 if k.startswith(\"en\"):\n",
    "#                     os.rename(os.path.join(new_path1,k),os.path.join(new_path1,\"English\",k))\n",
    "#                 elif k.startswith(\"de\"):\n",
    "#                     os.rename(os.path.join(new_path1,k),os.path.join(new_path1,\"German\",k))\n",
    "#                 elif k.startswith(\"es\"):\n",
    "#                     os.rename(os.path.join(new_path1,k),os.path.join(new_path1,\"Spanish\",k))\n",
    "#                 else:\n",
    "#                     continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path=os.path.join(path,\"train\",\"train\")\n",
    "test_path=os.path.join(path,\"test\",\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_16572\\3648061277.py:32: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if features==[]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female forEnglishdone\n",
      "Male forEnglishdone\n",
      "EnglishDone\n",
      "Female forGermandone\n",
      "Male forGermandone\n",
      "GermanDone\n",
      "Female forSpanishdone\n",
      "Male forSpanishdone\n",
      "SpanishDone\n",
      "Feature Extraction Done\n"
     ]
    }
   ],
   "source": [
    "true_values=[]\n",
    "count=0\n",
    "count_male=0\n",
    "count_female=0\n",
    "features=[]\n",
    "english_features=[]\n",
    "german_features=[]\n",
    "spanish_features=[]\n",
    "for folder in os.listdir(train_path):\n",
    "    folder_path=os.path.join(train_path,folder)\n",
    "    for file in os.listdir(folder_path):\n",
    "        if(count==max_count):\n",
    "            break\n",
    "        if(re.search(\"_f_\",file)):\n",
    "            if(count_female>=max_count/2):\n",
    "                continue\n",
    "            count_female+=1\n",
    "            if(count_female==max_count/2):\n",
    "                print(\"Female for \"+str(folder)+\" done\")\n",
    "\n",
    "        elif(re.search(\"_m_\",file)):\n",
    "            if(count_male>=max_count/2):\n",
    "                continue\n",
    "            count_male+=1\n",
    "            if(count_male==max_count/2):\n",
    "                print(\"Male for \"+str(folder)+\" done\")\n",
    "        \n",
    "        file_path=os.path.join(folder_path,file)\n",
    "        y=smile.process_file(file_path)\n",
    "        file_features=np.asarray(y)\n",
    "        if features==[]:\n",
    "            features=file_features\n",
    "        else:\n",
    "            features=np.concatenate((features,file_features),axis=0)\n",
    "        if(re.match(\"de\",file)):\n",
    "            true_values.append(0)\n",
    "        elif(re.match(\"en\",file)):\n",
    "            true_values.append(1)\n",
    "        elif(re.match(\"es\",file)):\n",
    "            true_values.append(2)\n",
    "        # print(count)\n",
    "        count+=1\n",
    "    # print(count)\n",
    "    # print(count_female)\n",
    "    # print(count_male)\n",
    "    count=0\n",
    "    count_female=0\n",
    "    count_male=0\n",
    "    # if folder==\"English\":\n",
    "    #     english_features=features\n",
    "    # elif folder==\"German\":\n",
    "    #     german_features=features\n",
    "    # elif folder==\"Spanish\":\n",
    "    #     spanish_features=features\n",
    "    print(str(folder)+\" Done\")\n",
    "true_values=np.array(true_values)   \n",
    "\n",
    "\n",
    "print(\"Feature Extraction Done\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 88)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(true_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_16572\\1653872597.py:10: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if test_features==[]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540\n",
      "Feature Extraction Done\n"
     ]
    }
   ],
   "source": [
    "true_values_test=[]\n",
    "test_features=[]\n",
    "count=0\n",
    "for folder in os.listdir(test_path):\n",
    "    folder_path=os.path.join(test_path,folder)\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path=os.path.join(folder_path,file)\n",
    "        y=smile.process_file(file_path)\n",
    "        file_features=np.asarray(y)\n",
    "        if test_features==[]:\n",
    "            test_features=file_features\n",
    "        else:\n",
    "            test_features=np.concatenate((test_features,file_features),axis=0)\n",
    "        if(re.match(\"de\",file)):\n",
    "            true_values_test.append(0)\n",
    "        elif(re.match(\"en\",file)):\n",
    "            true_values_test.append(1)\n",
    "        elif(re.match(\"es\",file)):\n",
    "            true_values_test.append(2)\n",
    "        count+=1\n",
    "true_values_test=np.array(true_values_test)   \n",
    "\n",
    "print(count)\n",
    "print(\"Feature Extraction Done\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# etc=ExtraTreesClassifier(n_estimators=50)\n",
    "# etc=etc.fit(features, true_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features=features[:,res]\n",
    "# test_features=test_features[:,res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540,)\n",
      "(540, 88)\n"
     ]
    }
   ],
   "source": [
    "print(true_values_test.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "wb=Workbook()\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Random Forest (checked and passed)\n",
    "# wb.create_sheet(\"Random Forest\")\n",
    "# ws=wb[\"Random Forest\"]\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# for i in range(1,test_features.shape[1]):\n",
    "#     th=-np.sort(-etc.feature_importances_)[i]\n",
    "#     res = [idx for idx, val in enumerate(etc.feature_importances_) if val > th]\n",
    "#     res=np.asarray(res)\n",
    "#     res.T\n",
    "#     cur_features=features[:,res]\n",
    "#     cur_test_features=test_features[:,res]\n",
    "    \n",
    "#     pipe1 = Pipeline([ ('std', StandardScaler()), ('Random_forest', RandomForestClassifier(n_estimators = 100))])\n",
    "                                    \n",
    "#     # fitting the data in the pipe\n",
    "#     pipe1.fit(cur_features, true_values)\n",
    "                                    \n",
    "#     # scoring data\n",
    "#     score=accuracy_score(true_values_test, pipe1.predict(cur_test_features))\n",
    "#     ws.cell(row=i+1,column=1).value=i+1\n",
    "#     ws.cell(row=i+1,column=2).value=score\n",
    "#     feature_list=\"\"\n",
    "#     for i in res:\n",
    "#         feature_list+=str(i)+\",\"\n",
    "#     ws.cell(row=i+1,column=3).value=feature_list\n",
    "    \n",
    "\n",
    "                                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sheet', 'SVM']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "wb.create_sheet(\"SVM - poly\")\n",
    "print(wb.sheetnames)\n",
    "wb.active=wb[\"SVM - poly\"]\n",
    "ws=wb.active\n",
    "# for i in range(5,13):\n",
    "#     th=-np.sort(-etc.feature_importances_)[i]\n",
    "#     res = [idx for idx, val in enumerate(etc.feature_importances_) if val > th]\n",
    "#     res=np.asarray(res)\n",
    "res=[24,38,58,60,68,70,76,78]\n",
    "res.T\n",
    "cur_features=features[:,res]\n",
    "cur_test_features=test_features[:,res]\n",
    "pipe4 = Pipeline([ ('std', StandardScaler()), ('SVM', SVC(kernel='poly',probability=True))])\n",
    "\n",
    "#    fitting the data in the pipe\n",
    "pipe4.fit(cur_features, true_values)\n",
    "score=accuracy_score(true_values_test, pipe4.predict(cur_test_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sheet', 'SVM', 'SVM - Linear']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "wb.create_sheet(\"SVM - Linear\")\n",
    "print(wb.sheetnames)\n",
    "wb.active=wb[\"SVM - Linear\"]\n",
    "ws=wb.active\n",
    "for i in range(5,15):\n",
    "    th=-np.sort(-etc.feature_importances_)[i]\n",
    "    res = [idx for idx, val in enumerate(etc.feature_importances_) if val > th]\n",
    "    res=np.asarray(res)\n",
    "    res.T\n",
    "    cur_features=features[:,res]\n",
    "    cur_test_features=test_features[:,res]\n",
    "    pipe4 = Pipeline([ ('std', StandardScaler()), ('SVM', SVC(kernel='linear',probability=True))])\n",
    "    feature_list=\"\"\n",
    "#    fitting the data in the pipe\n",
    "    pipe4.fit(cur_features, true_values)\n",
    "    score=accuracy_score(true_values_test, pipe4.predict(cur_test_features))\n",
    "    ws.cell(row=i+1,column=1).value=i+1\n",
    "    ws.cell(row=i+1,column=2).value=score\n",
    "    feature_list=\"\"\n",
    "    for j in res:\n",
    "        feature_list+=str(j)+\",\"\n",
    "    ws.cell(row=i+1,column=3).value=feature_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save(\"accuracy_score-SVM.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=Workbook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16572\\3261959798.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgerman_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGaussianMixture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcovariance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'diag'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgerman_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"German Model Done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0menglish_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGaussianMixture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcovariance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'diag'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menglish_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\mixture\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0mmixture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\mixture\\_base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0mComponent\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    770\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# n_components=64\n",
    "# max_iterations=200\n",
    "# german_model=GaussianMixture(n_components=n_components,covariance_type='diag',max_iter=max_iterations).fit(german_features)\n",
    "# print(\"German Model Done\")\n",
    "# english_model=GaussianMixture(n_components=n_components,covariance_type='diag',max_iter=max_iterations).fit(english_features)\n",
    "# print(\"English Model Done\")\n",
    "# spanish_model=GaussianMixture(n_components=n_components,covariance_type='diag',max_iter=max_iterations).fit(features_spanish)\n",
    "# print(\"Spanish Model Done\")\n",
    "# wb.create_sheet(\"GMM\")\n",
    "# print(wb.sheetnames)\n",
    "# wb.active=wb[\"GMM\"]\n",
    "# ws=wb.active\n",
    "# try:\n",
    "#     for i in range(0,10):\n",
    "#         th=-np.sort(-etc.feature_importances_)[i]\n",
    "#         res = [idx for idx, val in enumerate(etc.feature_importances_) if val > th]\n",
    "#         res=np.asarray(res)\n",
    "#         res.T\n",
    "#         cur_features=features[:,res]\n",
    "#         cur_test_features=test_features[:,res]\n",
    "#         pipe5 = Pipeline([ ('std', StandardScaler()), (GaussianMixture(n_components=n_components,covariance_type='diag',max_iter=max_iterations))])\n",
    "        \n",
    "#     #    fitting the data in the pipe\n",
    "#         pipe5.fit(cur_features, true_values)\n",
    "#         score=accuracy_score(true_values_test, pipe5.predict(cur_test_features))\n",
    "#         ws.cell(row=i+1,column=1).value=i+1\n",
    "#         ws.cell(row=i+1,column=2).value=score\n",
    "# except:\n",
    "#     pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wb.save(\"accuracy_score -GMM .xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores=np.array(Scores)\n",
    "# pred=[]\n",
    "# for score in Scores:\n",
    "#     pred.append(np.argmax(score))\n",
    "# print(accuracy_score(true_values_TEST,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# knn.fit(Scores, true_values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c25269a4018224bb4e3cb6b79397037e31419b0dedc1b97e47175df2e08dbf7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
